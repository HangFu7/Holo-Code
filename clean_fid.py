import argparse
import json
import torch
import os
import random
import numpy as np
from tqdm import tqdm
# ä¿æŒå¼•ç”¨ä¸€è‡´ï¼Œç¡®ä¿ç¯å¢ƒå…¼å®¹
from inverse_stable_diffusion import InversableStableDiffusionPipeline
from diffusers import DPMSolverMultistepScheduler
from optim_utils import *
from pytorch_fid.fid_score import *

# [å…³é”®] æ‰‹åŠ¨å®šä¹‰éšæœºç§å­å‡½æ•°ï¼Œç¡®ä¿å’Œ gaussian_shading_fid è¡Œä¸ºä¸€è‡´ä¸”ä¸æŠ¥é”™
def set_random_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def main(args):
    print(f"ğŸš€ Starting CLEAN (No Watermark) Generation...")

    # 1. åˆå§‹åŒ–æ¨¡å‹ (é€»è¾‘ä¸¥æ ¼å¯¹é½)
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # å°è¯•åŠ è½½ Schedulerï¼Œå¢åŠ å®¹é”™ (å’Œä½ é‡åˆ°çš„ OSError æœ‰å…³)
    try:
        scheduler = DPMSolverMultistepScheduler.from_pretrained(args.model_path, subfolder='scheduler')
    except OSError:
        print("âš ï¸ Warning: Could not load scheduler config from subfolder. Trying default config...")
        scheduler = DPMSolverMultistepScheduler.from_config(args.model_path)

    pipe = InversableStableDiffusionPipeline.from_pretrained(
            args.model_path,
            scheduler=scheduler,
            torch_dtype=torch.float16,
            revision='fp16',
    )
    pipe.safety_checker = None
    pipe = pipe.to(device)

    # 2. åŠ è½½æ•°æ® (é€»è¾‘ä¸¥æ ¼å¯¹é½)
    print(f"Loading prompts from {args.prompt_file}...")
    with open(args.prompt_file) as f:
        dataset = json.load(f)
        image_list = dataset['images']
        annotation_list = dataset['annotations']
        
        # é•¿åº¦æˆªæ–­æ£€æŸ¥
        real_num = min(len(image_list), len(annotation_list))
        if args.num > real_num:
            print(f"Warning: args.num ({args.num}) is larger than dataset size. Truncating to {real_num}.")
            args.num = real_num

    # 3. è®¾ç½®è¾“å‡ºç›®å½•
    base_dir = os.path.join('./fid_outputs/coco', args.run_name)
    w_dir = os.path.join(base_dir, 'w_gen')
    os.makedirs(w_dir, exist_ok=True)
    os.makedirs(args.output_path, exist_ok=True)

    print(f"Generating {args.num} images to: {w_dir}")

    # 4. ç”Ÿæˆå¾ªç¯
    for i in tqdm(range(args.num)):
        seed = i + args.gen_seed
        
        # A. è·å–æ•°æ®
        current_prompt = annotation_list[i]['caption']
        file_name = image_list[i]['file_name']
        
        # B. è·¯å¾„å¤„ç†
        save_name = file_name.replace('.jpg', '.png')
        save_path = os.path.join(w_dir, save_name)

        # C. æ ¸å¿ƒå·®å¼‚ï¼šç”Ÿæˆçº¯å‡€é«˜æ–¯å™ªå£° (Standard Gaussian Noise)
        # ä¸¥æ ¼æ§åˆ¶ç§å­
        set_random_seed(seed)
        
        # è®¡ç®— Latent å½¢çŠ¶ (Batch=1, Channels=4, H/8, W/8)
        latent_shape = (1, 4, args.image_length // 8, args.image_length // 8)
        
        # ç›´æ¥ä½¿ç”¨ torch.randn ç”Ÿæˆæ ‡å‡†æ­£æ€åˆ†å¸ƒå™ªå£° (Clean)
        init_latents = torch.randn(
            latent_shape,
            device=device,
            dtype=torch.float16
        )
        
        # D. æ¨ç†
        outputs = pipe(
            current_prompt,
            num_images_per_prompt=args.num_images,
            guidance_scale=args.guidance_scale,
            num_inference_steps=args.num_inference_steps,
            height=args.image_length,
            width=args.image_length,
            latents=init_latents, # ä¼ å…¥çº¯å‡€å™ªå£°
        )
        image_w = outputs.images[0]
        image_w.save(save_path)

    # 5. è®¡ç®— FID
    print(f"\n>>> Calculating FID for CLEAN images...")
    print(f"    GT: {args.gt_folder}")
    print(f"    Gen: {w_dir}")

    if not os.path.exists(args.gt_folder):
        print("Error: GT folder not found.")
        return

    try:
        num_cpus = len(os.sched_getaffinity(0))
    except AttributeError:
        num_cpus = os.cpu_count()
    num_workers = min(num_cpus, 8) if num_cpus is not None else 0
    
    try:
        fid_value = calculate_fid_given_paths(
            [args.gt_folder, w_dir],
            50,
            device,
            2048,
            num_workers
        )
        print(f'\n{"="*40}')
        print(f'âœ¨ RESULT: CLEAN | FID: {fid_value}')
        print(f'{"="*40}\n')
        
        with open(os.path.join(args.output_path, 'official_fid_results.txt'), "a") as file:
            file.write(f'Algo: Clean | Run: {args.run_name} | FID: {fid_value}\n')
            
    except Exception as e:
        print(f"âŒ Error calculating FID: {e}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Official Clean FID Calculation')
    
    parser.add_argument('--run_name', default="Official_Clean")
    parser.add_argument('--num', default=5000, type=int)
    
    # è·¯å¾„å‚æ•°
    parser.add_argument('--prompt_file', default='./fid_outputs/coco/meta_data.json')
    parser.add_argument('--gt_folder', default='./fid_outputs/coco/ground_truth')
    parser.add_argument('--output_path', default='./output/')
    # é»˜è®¤å€¼æ”¹ä¸ºæœ¬åœ°ç›¸å¯¹è·¯å¾„
    parser.add_argument('--model_path', default='./stable-diffusion-2-1-base') 
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument('--image_length', default=512, type=int)
    parser.add_argument('--num_images', default=1, type=int)
    parser.add_argument('--guidance_scale', default=7.5, type=float)
    parser.add_argument('--num_inference_steps', default=50, type=int)
    parser.add_argument('--gen_seed', default=0, type=int)

    args = parser.parse_args()
    main(args)